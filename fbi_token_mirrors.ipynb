{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import plotly.graph_objects as go\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv('export-token-0x16ca471ae755f8a2cd4ec315a4a7439dcfebe54c.csv')\n",
    "\n",
    "# Convert Quantity to numeric, removing commas\n",
    "df['Quantity'] = df['Quantity'].str.replace(',', '').astype(float)\n",
    "\n",
    "# Replace Method based on conditions\n",
    "df.loc[(df['From'] == 'WETHContract') & (df['Method'] == '-'), 'Method'] = 'UniSwapEthforNexF'\n",
    "df.loc[(df['To'] == 'WETHContract') & (df['Method'] == '-'), 'Method'] = 'BoughtNexFwithEth'\n",
    "\n",
    "# Display the first few rows to verify changes\n",
    "print(df.head())\n",
    "\n",
    "# Save the modified DataFrame back to a CSV file\n",
    "df.to_csv('modified_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Addresses DF and encode methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_address = 'WETHContract'\n",
    "\n",
    "# Create a new DataFrame to store address statistics\n",
    "addresses = pd.DataFrame(columns=['Address', 'NetAmount', 'Interactions', 'Method_encoded', 'First_Interaction', 'Last_Interaction'])\n",
    "\n",
    "# Function to update address statistics\n",
    "def update_address_stats(address, amount, encoded_method, timestamp):\n",
    "    if address not in addresses['Address'].values:\n",
    "        addresses.loc[len(addresses)] = [address, 0, 0, defaultdict(int), timestamp, timestamp]\n",
    "    \n",
    "    idx = addresses.index[addresses['Address'] == address][0]\n",
    "    addresses.at[idx, 'NetAmount'] += amount\n",
    "    addresses.at[idx, 'Interactions'] += 1\n",
    "    addresses.at[idx, 'Method_encoded'][encoded_method] += 1\n",
    "    addresses.at[idx, 'First_Interaction'] = min(addresses.at[idx, 'First_Interaction'], timestamp)\n",
    "    addresses.at[idx, 'Last_Interaction'] = max(addresses.at[idx, 'Last_Interaction'], timestamp)\n",
    "\n",
    "# Encode 'Method' strings\n",
    "method_encoding = {method: i for i, method in enumerate(df['Method'].unique())}\n",
    "df['EncodedMethod'] = df['Method'].map(method_encoding)\n",
    "\n",
    "# Analyze each transaction\n",
    "for _, row in df.iterrows():\n",
    "    if row['From'] != contract_address:\n",
    "        update_address_stats(row['From'], -row['Quantity'], row['EncodedMethod'], row['UnixTimestamp'])\n",
    "    \n",
    "    if row['To'] != contract_address:\n",
    "        update_address_stats(row['To'], row['Quantity'], row['EncodedMethod'], row['UnixTimestamp'])\n",
    "\n",
    "# Convert 'Method_encoded' to a more readable format\n",
    "addresses['Method_encoded'] = addresses['Method_encoded'].apply(lambda x: dict(x))\n",
    "\n",
    "# Convert Unix timestamps to datetime\n",
    "addresses['First_Interaction'] = pd.to_datetime(addresses['First_Interaction'], unit='s')\n",
    "addresses['Last_Interaction'] = pd.to_datetime(addresses['Last_Interaction'], unit='s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate interaction duration\n",
    "addresses['Interaction_Duration'] = addresses['Last_Interaction'] - addresses['First_Interaction']\n",
    "\n",
    "# Statistical summary of the addresses DataFrame\n",
    "summary = {\n",
    "    'Total Addresses': len(addresses),\n",
    "    'Total NetAmount': addresses['NetAmount'].sum(),\n",
    "    'Average NetAmount': addresses['NetAmount'].mean(),\n",
    "    'Total Interactions': addresses['Interactions'].sum(),\n",
    "    'Average Interactions': addresses['Interactions'].mean(),\n",
    "    'Unique Methods': len(method_encoding),\n",
    "    'Average Interaction Duration': addresses['Interaction_Duration'].mean(),\n",
    "    'Median Interaction Duration': addresses['Interaction_Duration'].median(),\n",
    "}\n",
    "\n",
    "print(\"\\nStatistical Summary:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Method distribution analysis\n",
    "method_distribution = defaultdict(int)\n",
    "for methods in addresses['Method_encoded']:\n",
    "    for method, count in methods.items():\n",
    "        method_distribution[method] += count\n",
    "\n",
    "total_method_calls = sum(method_distribution.values())\n",
    "method_distribution_percentage = {method: (count / total_method_calls) * 100 for method, count in method_distribution.items()}\n",
    "\n",
    "# Create a bar plot for method distribution\n",
    "methods = list(method_distribution_percentage.keys())\n",
    "percentages = list(method_distribution_percentage.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(methods, percentages, color='skyblue')\n",
    "plt.xlabel('Encoded Method')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.title('FBI Project Token Mirrors\\n Contract Method Distribution')\n",
    "plt.xticks(methods)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(f'contract_methods_distribution.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "# Time series analysis\n",
    "df['Timestamp'] = pd.to_datetime(df['UnixTimestamp'], unit='s')\n",
    "df.set_index('Timestamp', inplace=True)\n",
    "\n",
    "# Daily transaction count\n",
    "daily_transactions = df.resample('D').size()\n",
    "\n",
    "# Daily net amount\n",
    "daily_net_amount = df.resample('D')['Quantity'].sum()\n",
    "\n",
    "print(\"\\nDaily Transaction Summary:\")\n",
    "print(daily_transactions.describe())\n",
    "\n",
    "print(\"\\nDaily Net Amount Summary:\")\n",
    "print(daily_net_amount.describe())\n",
    "\n",
    "# Optional: Save the results to CSV files\n",
    "addresses.to_csv('address_statistics.csv', index=False)\n",
    "pd.DataFrame(summary, index=[0]).to_csv('statistical_summary.csv', index=False)\n",
    "pd.DataFrame(method_distribution_percentage, index=[0]).to_csv('method_distribution.csv')\n",
    "daily_transactions.to_csv('daily_transactions.csv')\n",
    "daily_net_amount.to_csv('daily_net_amount.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Wavelet analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Unix timestamp to datetime\n",
    "df['UnixTimestamp'] = pd.to_datetime(df['UnixTimestamp'], unit='s')\n",
    "\n",
    "# Perform wavelet analysis\n",
    "quantity_series = df['Quantity'].values\n",
    "time_series = df['UnixTimestamp'].values\n",
    "wavelet = 'db4'  # Daubechies 4 wavelet\n",
    "max_level = pywt.dwt_max_level(len(quantity_series), pywt.Wavelet(wavelet).dec_len)\n",
    "coeffs = pywt.wavedec(quantity_series, wavelet, level=max_level)\n",
    "\n",
    "# Calculate summary statistics across all levels\n",
    "summary_stats = {\n",
    "    'Mean': np.mean([np.mean(coeff) for coeff in coeffs]),\n",
    "    'Median': np.median([np.median(coeff) for coeff in coeffs]),\n",
    "    'Std Dev': np.mean([np.std(coeff) for coeff in coeffs]),\n",
    "    'Skewness': np.mean([stats.skew(coeff) for coeff in coeffs]),\n",
    "    'Kurtosis': np.mean([stats.kurtosis(coeff) for coeff in coeffs]),\n",
    "    'Max Absolute Value': np.max([np.max(np.abs(coeff)) for coeff in coeffs]),\n",
    "    'Total Energy': np.sum([np.sum(np.abs(coeff)**2) for coeff in coeffs])\n",
    "}\n",
    "\n",
    "# Visualize all frequency components with log scale\n",
    "plt.figure(figsize=(20, 10))\n",
    "ax = plt.gca()\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, len(coeffs)))\n",
    "\n",
    "for i, (coeff, color) in enumerate(zip(coeffs, colors)):\n",
    "    # Interpolate coefficients to match original time series length\n",
    "    coeff_interp = np.interp(np.linspace(0, 1, len(time_series)), \n",
    "                             np.linspace(0, 1, len(coeff)), coeff)\n",
    "    ax.plot(time_series, coeff_interp, color=color, alpha=0.7, \n",
    "            label=f'Level {i}')\n",
    "\n",
    "ax.set_title('FBI Operation Token Mirrors\\nWavelet Decomposition of Token Quantity Time Series')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Coefficient Value')\n",
    "\n",
    "# Create a text box with summary statistics and explanation\n",
    "stats_text = \"Wavelet Analysis:\\n\\n\"\n",
    "\n",
    "stats_text += \"1. Each line color represents a different frequency range\\n\"\n",
    "stats_text += \"2. Lower levels show high-frequency details\\n\"\n",
    "stats_text += \"3. Higher levels show low-frequency approximations\\n\"\n",
    "stats_text += \"4. Coefficients indicate the strength of each frequency component\\n\"\n",
    "stats_text += \"5. Patterns across levels reveal multi-scale structure in the data\"\n",
    "\n",
    "# Add the statistics text box to the top right, below the legend\n",
    "plt.text(0.1, 0.95, stats_text, transform=ax.transAxes, fontsize=12,\n",
    "         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Adjust the layout to prevent overlapping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure with an informative title\n",
    "plt.savefig(f'wavelet_decomposition_{wavelet}_level{max_level}.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"Wavelet decomposition plot saved as 'wavelet_decomposition_{wavelet}_level{max_level}.png'\")\n",
    "\n",
    "# Print wavelet statistics to console\n",
    "print(\"\\nWavelet Analysis Statistics:\")\n",
    "for stat, value in summary_stats.items():\n",
    "    print(f\"  {stat}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of Wavelet Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution of coefficients with log scale\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, coeff in enumerate(coeffs):\n",
    "    plt.hist(coeff, bins=30, alpha=0.5, label=f'Level {i}')\n",
    "plt.title('FBI Operation Token Mirrors\\nDistribution of Wavelet Coefficients')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.yscale('log')  # Use log scale for y-axis\n",
    "plt.legend()\n",
    "plt.savefig('wavelet_coefficient_distribution_log_scale.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an interactive visualization of the transaction interactions with the contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode 'Method' column in the original DataFrame\n",
    "le = LabelEncoder()\n",
    "df['Method_encoded'] = le.fit_transform(df['Method'])\n",
    "\n",
    "# Create a new DataFrame to store address statistics\n",
    "addresses = pd.DataFrame(columns=['Address', 'NetAmount', 'Interactions', 'Method_encoded'])\n",
    "\n",
    "# Function to update address statistics\n",
    "def update_address_stats(address, amount, encoded_method):\n",
    "    if address not in addresses['Address'].values:\n",
    "        addresses.loc[len(addresses)] = [address, 0, 0, []]\n",
    "    \n",
    "    idx = addresses.index[addresses['Address'] == address][0]\n",
    "    addresses.at[idx, 'NetAmount'] += amount\n",
    "    addresses.at[idx, 'Interactions'] += 1\n",
    "    addresses.at[idx, 'Method_encoded'].append(encoded_method)\n",
    "\n",
    "# Analyze each transaction\n",
    "contract_address = 'WETHContract'\n",
    "for _, row in df.iterrows():\n",
    "    if row['From'] != contract_address:\n",
    "        update_address_stats(row['From'], -row['Quantity'], row['Method_encoded'])\n",
    "    \n",
    "    if row['To'] != contract_address:\n",
    "        update_address_stats(row['To'], row['Quantity'], row['Method_encoded'])\n",
    "\n",
    "# Convert Method_encoded lists to a single representative value (e.g., most frequent)\n",
    "addresses['Method_encoded'] = addresses['Method_encoded'].apply(lambda x: max(set(x), key=x.count) if x else np.nan)\n",
    "\n",
    "# Create the interactive scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.sign(addresses['NetAmount']) * np.log1p(abs(addresses['NetAmount'])),\n",
    "    y=np.sign(addresses['Interactions']) * np.log1p(abs(addresses['Interactions'])),\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=np.log1p(abs(addresses['NetAmount'])) * 1.2,\n",
    "        color=addresses['Method_encoded'],\n",
    "        colorscale='Viridis',\n",
    "        colorbar=dict(title='Method'),\n",
    "        showscale=True\n",
    "    ),\n",
    "    customdata=addresses['Address'],  # Pass addresses as custom data for callback\n",
    "    text=[f\"Address: {addr}<br>\"\n",
    "          f\"Interactions: {inter:,}<br>\"\n",
    "          f\"Net Amount: {net:.2f}<br>\"\n",
    "          f\"Encoded Method: {method}\"\n",
    "          for addr, inter, net, method in addresses[['Address', 'Interactions', 'NetAmount', 'Method_encoded']].itertuples(index=False)],\n",
    "    hoverinfo='text'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"FBI Operation Token Mirrors<br>Address Interactions vs Net Amount (Log Scale)\",\n",
    "    xaxis_title=\"Log(Net Amount of NexF Tokens)\",\n",
    "    yaxis_title=\"Log(Number of Interactions) with<br>NexF Contract @ 0x16ca471ae755f8a2cd4ec315a4a7439dcfebe54c\",\n",
    "    xaxis=dict(zeroline=False),\n",
    "    yaxis=dict(zeroline=False),\n",
    "    hovermode='closest',\n",
    "    width=1000,\n",
    "    height=800\n",
    ")\n",
    "\n",
    "# Save the interactive plot\n",
    "fig.write_html(\"address_interactions.html\", full_html=False)\n",
    "\n",
    "print(\"\\nInteractive Address Interactions vs Net Amount Visualization saved as 'address_interactions.html'\")\n",
    "\n",
    "# Add JavaScript for clipboard functionality\n",
    "html_content = \"\"\"\n",
    "<div id=\"myDiv\"></div>\n",
    "<script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "<script>\n",
    "var myPlot = document.getElementById('myDiv');\n",
    "Plotly.newPlot(myPlot, %s);\n",
    "\n",
    "myPlot.on('plotly_click', function(data){\n",
    "    var address = data.points[0].customdata; // Access customdata directly\n",
    "    navigator.clipboard.writeText(address).then(function() {\n",
    "        alert('Address copied to clipboard: ' + address);\n",
    "    }, function(err) {\n",
    "        console.error('Could not copy text: ', err);\n",
    "    });\n",
    "});\n",
    "</script>\n",
    "\"\"\" % fig.to_json()\n",
    "\n",
    "with open(\"address_interactions.html\", \"w\") as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "print(\"HTML file with clipboard functionality has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Convert Method into categorical data\n",
    "df['Method'] = pd.Categorical(df['Method'])\n",
    "\n",
    "# Step 4: Analyze To and From data\n",
    "to_from_pairs = list(zip(df['To'], df['From']))\n",
    "pair_counts = Counter(to_from_pairs)\n",
    "\n",
    "# Create a mathematical model of the categorical data\n",
    "total_transactions = len(to_from_pairs)\n",
    "pair_distribution = {pair: count / total_transactions for pair, count in pair_counts.items()}\n",
    "\n",
    "# Sort pairs by frequency\n",
    "sorted_pairs = sorted(pair_distribution.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print results\n",
    "print(f\"Total number of unique (To, From) pairs: {len(pair_counts)}\")\n",
    "print(\"\\nTop 10 most frequent (To, From) pairs and their distribution:\")\n",
    "for pair, dist in sorted_pairs[:10]:\n",
    "    print(f\"Pair: {pair}, Distribution: {dist:.4f}, Count: {pair_counts[pair]}\")\n",
    "\n",
    "# Visualize distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(sorted_pairs)), [dist for _, dist in sorted_pairs])\n",
    "plt.title('FBI Operation Token Mirror\\nDistribution of (Sender, Receiver) Pairs')\n",
    "plt.xlabel('Pair Index (sorted by frequency)')\n",
    "plt.ylabel('Distribution')\n",
    "plt.savefig('pair_distribution.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
